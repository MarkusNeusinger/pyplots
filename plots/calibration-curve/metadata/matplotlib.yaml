library: matplotlib
specification_id: calibration-curve
created: '2025-12-26T19:38:04Z'
updated: '2025-12-26T19:44:38Z'
generated_by: claude-opus-4-5-20251101
workflow_run: 20528201914
issue: 0
python_version: 3.13.11
library_version: 3.10.8
preview_url: https://storage.googleapis.com/pyplots-images/plots/calibration-curve/matplotlib/plot.png
preview_thumb: https://storage.googleapis.com/pyplots-images/plots/calibration-curve/matplotlib/plot_thumb.png
preview_html: null
quality_score: 93
impl_tags:
  dependencies: []
  techniques:
  - subplots
  patterns:
  - data-generation
  - iteration-over-groups
  dataprep:
  - binning
  styling:
  - alpha-blending
review:
  strengths:
  - Excellent multi-model comparison showing well-calibrated, overconfident, and underconfident
    classifiers
  - Includes histogram subplot as suggested in spec for showing prediction distributions
  - Brier scores integrated into legend for quick comparison
  - Clean separation of calibration curve calculation logic
  - Colorblind-friendly palette with distinct marker shapes for each model
  - Professional layout with appropriate subplot height ratios
  weaknesses:
  - Axis labels lack units or additional context
  - Could use more distinctive matplotlib features like fill_between for confidence
    bands
  image_description: The plot consists of two vertically stacked subplots. The main
    upper subplot shows three calibration curves against a dashed black diagonal reference
    line representing perfect calibration. The "Well-Calibrated" model (blue line
    with circle markers) follows closely along the diagonal. The "Overconfident" model
    (yellow line with square markers) shows a steep S-curve pattern, jumping sharply
    from 0 to 1 around the 0.4-0.6 probability range. The "Underconfident" model (pink/magenta
    line with triangle markers) shows a flatter curve. Each model displays its Brier
    score in the legend (0.101, 0.020, 0.181 respectively). The lower subplot shows
    a histogram of predicted probability distributions for all three models, clearly
    showing that the overconfident model clusters predictions near 0 and 1, while
    the underconfident model clusters near 0.5, and the well-calibrated model has
    a more spread distribution. All text is clearly readable, colors are distinct
    and colorblind-friendly, and the layout is well-balanced.
  criteria_checklist:
    visual_quality:
      score: 38
      max: 40
      items:
      - id: VQ-01
        name: Text Legibility
        score: 10
        max: 10
        passed: true
        comment: Title at 24pt, axis labels at 20pt, tick labels at 16pt, legend at
          16pt - all perfectly readable
      - id: VQ-02
        name: No Overlap
        score: 8
        max: 8
        passed: true
        comment: No overlapping text or elements anywhere
      - id: VQ-03
        name: Element Visibility
        score: 7
        max: 8
        passed: true
        comment: Markers at size 12 with linewidth 3 are clearly visible; could be
          slightly larger but acceptable
      - id: VQ-04
        name: Color Accessibility
        score: 5
        max: 5
        passed: true
        comment: Blue, yellow, and pink/magenta are distinguishable for colorblind
          users
      - id: VQ-05
        name: Layout Balance
        score: 5
        max: 5
        passed: true
        comment: Two-subplot layout with 3:1 height ratio uses canvas effectively
      - id: VQ-06
        name: Axis Labels
        score: 1
        max: 2
        passed: true
        comment: Labels are descriptive ("Mean Predicted Probability", "Fraction of
          Positives", "Count") but lack units
      - id: VQ-07
        name: Grid & Legend
        score: 2
        max: 2
        passed: true
        comment: Grid at alpha=0.3 with dashed style is subtle, legends well-placed
    spec_compliance:
      score: 25
      max: 25
      items:
      - id: SC-01
        name: Plot Type
        score: 8
        max: 8
        passed: true
        comment: Correct calibration/reliability diagram with diagonal reference
      - id: SC-02
        name: Data Mapping
        score: 5
        max: 5
        passed: true
        comment: X-axis shows mean predicted probability, Y-axis shows fraction of
          positives
      - id: SC-03
        name: Required Features
        score: 5
        max: 5
        passed: true
        comment: Has diagonal reference line, 10 bins, Brier scores displayed, histogram
          subplot for prediction distribution, multiple model comparison with distinct
          colors and legend
      - id: SC-04
        name: Data Range
        score: 3
        max: 3
        passed: true
        comment: Both axes range from 0 to 1 as appropriate for probabilities
      - id: SC-05
        name: Legend Accuracy
        score: 2
        max: 2
        passed: true
        comment: Legends correctly identify each model with Brier scores
      - id: SC-06
        name: Title Format
        score: 2
        max: 2
        passed: true
        comment: Uses exact format "calibration-curve · matplotlib · pyplots.ai"
    data_quality:
      score: 18
      max: 20
      items:
      - id: DQ-01
        name: Feature Coverage
        score: 7
        max: 8
        passed: true
        comment: Shows well-calibrated, overconfident, and underconfident models demonstrating
          key calibration patterns; histogram clearly shows distribution differences
      - id: DQ-02
        name: Realistic Context
        score: 6
        max: 7
        passed: true
        comment: Simulated classifier outputs are plausible; using 35% positive rate
          is realistic for imbalanced classification
      - id: DQ-03
        name: Appropriate Scale
        score: 5
        max: 5
        passed: true
        comment: 2000 samples, probabilities correctly bounded 0-1, Brier scores in
          realistic range
    code_quality:
      score: 10
      max: 10
      items:
      - id: CQ-01
        name: KISS Structure
        score: 3
        max: 3
        passed: true
        comment: Follows imports → data → plot → save structure, no functions or classes
      - id: CQ-02
        name: Reproducibility
        score: 3
        max: 3
        passed: true
        comment: Uses np.random.seed(42)
      - id: CQ-03
        name: Clean Imports
        score: 2
        max: 2
        passed: true
        comment: Only imports matplotlib.pyplot and numpy, both used
      - id: CQ-04
        name: No Deprecated API
        score: 1
        max: 1
        passed: true
        comment: All APIs are current
      - id: CQ-05
        name: Output Correct
        score: 1
        max: 1
        passed: true
        comment: Saves as 'plot.png'
    library_features:
      score: 2
      max: 5
      items:
      - id: LF-01
        name: Uses distinctive library features
        score: 2
        max: 5
        passed: false
        comment: Uses matplotlib correctly with subplots and gridspec_kw for height
          ratios, but doesn't leverage more distinctive matplotlib features like fill_between
          for confidence intervals or custom tick formatting
  verdict: APPROVED
