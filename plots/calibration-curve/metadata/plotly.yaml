library: plotly
specification_id: calibration-curve
created: '2025-12-26T19:37:55Z'
updated: '2025-12-26T19:44:29Z'
generated_by: claude-opus-4-5-20251101
workflow_run: 20528201899
issue: 0
python_version: 3.13.11
library_version: 6.5.0
preview_url: https://storage.googleapis.com/pyplots-images/plots/calibration-curve/plotly/plot.png
preview_thumb: https://storage.googleapis.com/pyplots-images/plots/calibration-curve/plotly/plot_thumb.png
preview_html: https://storage.googleapis.com/pyplots-images/plots/calibration-curve/plotly/plot.html
quality_score: 93
impl_tags:
  dependencies: []
  techniques:
  - subplots
  patterns:
  - data-generation
  - iteration-over-groups
  dataprep:
  - binning
  styling: []
review:
  strengths:
  - Excellent implementation of calibration curve concept with comparison of two models
    (calibrated vs overconfident)
  - Perfect compliance with specification including optional histogram subplot for
    prediction distribution
  - Brier scores displayed in legend provide quantitative calibration metrics
  - Clean, professional visual design with appropriate color choices
  - Proper use of plotly subplots with appropriate row height ratios
  weaknesses:
  - Histogram subplot could benefit from more visible distinction between overlapping
    distributions (consider side-by-side instead of overlay)
  - Does not leverage plotly interactive hover features to show bin details on mouseover
  image_description: 'The plot displays a calibration curve visualization with two
    panels. The top panel (main calibration curve) shows three elements: a gray dashed
    diagonal line representing perfect calibration, a blue line with circular markers
    for a "Calibrated Model" (Brier: 0.206), and a yellow/gold line with diamond markers
    for an "Overconfident Model" (Brier: 0.219). The calibrated model follows the
    diagonal more closely, while the overconfident model shows the characteristic
    S-curve pattern (above the diagonal for low probabilities, below for high probabilities).
    The bottom panel shows overlaid histograms of the prediction distributions for
    both models - the calibrated model (blue) has a more uniform distribution across
    probabilities, while the overconfident model (yellow) shows concentration at the
    extremes (near 0 and 1). The title "calibration-curve · plotly · pyplots.ai" is
    centered at the top. All text is clearly readable with appropriate font sizes.'
  criteria_checklist:
    visual_quality:
      score: 37
      max: 40
      items:
      - id: VQ-01
        name: Text Legibility
        score: 10
        max: 10
        passed: true
        comment: Title at 32pt, axis labels at 22pt, tick labels at 18pt - all clearly
          readable
      - id: VQ-02
        name: No Overlap
        score: 8
        max: 8
        passed: true
        comment: No overlapping text elements anywhere
      - id: VQ-03
        name: Element Visibility
        score: 8
        max: 8
        passed: true
        comment: Markers size 14 with width 4 lines are well-sized for the data density
          (10 points per model)
      - id: VQ-04
        name: Color Accessibility
        score: 5
        max: 5
        passed: true
        comment: Blue (#306998) and yellow (#FFD43B) provide excellent contrast and
          are colorblind-safe
      - id: VQ-05
        name: Layout Balance
        score: 4
        max: 5
        passed: true
        comment: Good use of subplots with 70/30 split, slight reduction for histogram
          being somewhat compressed
      - id: VQ-06
        name: Axis Labels
        score: 2
        max: 2
        passed: true
        comment: 'Descriptive labels: "Mean Predicted Probability", "Fraction of Positives",
          "Count"'
      - id: VQ-07
        name: Grid & Legend
        score: 0
        max: 2
        passed: false
        comment: Grid is subtle (alpha 0.1), but legend lacks border visibility in
          some contexts
    spec_compliance:
      score: 25
      max: 25
      items:
      - id: SC-01
        name: Plot Type
        score: 8
        max: 8
        passed: true
        comment: Correct calibration curve (reliability diagram) implementation
      - id: SC-02
        name: Data Mapping
        score: 5
        max: 5
        passed: true
        comment: X=mean predicted probability, Y=fraction of positives correctly mapped
      - id: SC-03
        name: Required Features
        score: 5
        max: 5
        passed: true
        comment: Has diagonal reference line, 10 bins, Brier scores displayed, histogram
          subplot
      - id: SC-04
        name: Data Range
        score: 3
        max: 3
        passed: true
        comment: Both axes properly show 0-1 range
      - id: SC-05
        name: Legend Accuracy
        score: 2
        max: 2
        passed: true
        comment: Legend correctly identifies all elements with Brier scores
      - id: SC-06
        name: Title Format
        score: 2
        max: 2
        passed: true
        comment: 'Correct format: "calibration-curve · plotly · pyplots.ai"'
    data_quality:
      score: 18
      max: 20
      items:
      - id: DQ-01
        name: Feature Coverage
        score: 7
        max: 8
        passed: true
        comment: Shows well-calibrated vs overconfident models, demonstrating calibration
          concepts effectively; minor deduction as both models have similar Brier
          scores
      - id: DQ-02
        name: Realistic Context
        score: 6
        max: 7
        passed: true
        comment: Simulated classifier predictions are plausible, though could be more
          domain-specific
      - id: DQ-03
        name: Appropriate Scale
        score: 5
        max: 5
        passed: true
        comment: All values in valid 0-1 probability range, 2000 samples appropriate
    code_quality:
      score: 10
      max: 10
      items:
      - id: CQ-01
        name: KISS Structure
        score: 3
        max: 3
        passed: true
        comment: 'Linear script structure: imports → data → plot → save'
      - id: CQ-02
        name: Reproducibility
        score: 3
        max: 3
        passed: true
        comment: Uses np.random.seed(42)
      - id: CQ-03
        name: Clean Imports
        score: 2
        max: 2
        passed: true
        comment: Only numpy and plotly imports, all used
      - id: CQ-04
        name: No Deprecated API
        score: 1
        max: 1
        passed: true
        comment: Uses current plotly API
      - id: CQ-05
        name: Output Correct
        score: 1
        max: 1
        passed: true
        comment: Saves as plot.png (and plot.html)
    library_features:
      score: 3
      max: 5
      items:
      - id: LF-01
        name: Uses distinctive library features
        score: 3
        max: 5
        passed: true
        comment: Uses subplots, interactive features via HTML export, but doesn't
          leverage plotly-specific features like hover customization or animations
  verdict: APPROVED
