library: altair
specification_id: roc-curve
created: '2025-12-26T17:37:31Z'
updated: '2025-12-26T17:45:58Z'
generated_by: claude-opus-4-5-20251101
workflow_run: 20526594069
issue: 0
python_version: 3.13.11
library_version: 6.0.0
preview_url: https://storage.googleapis.com/pyplots-images/plots/roc-curve/altair/plot.png
preview_thumb: https://storage.googleapis.com/pyplots-images/plots/roc-curve/altair/plot_thumb.png
preview_html: https://storage.googleapis.com/pyplots-images/plots/roc-curve/altair/plot.html
quality_score: 91
impl_tags:
  dependencies: []
  techniques:
  - layer-composition
  - html-export
  patterns:
  - data-generation
  dataprep: []
  styling: []
review:
  strengths:
  - Excellent color scheme with blue/yellow/gray that is accessible and visually appealing
  - Clean declarative Altair code with proper encoding types (:Q, :N)
  - AUC values prominently displayed in legend for easy comparison
  - Diagonal reference line clearly distinguished with dashed style
  - Square aspect ratio appropriate for ROC curves
  - Both static PNG and interactive HTML outputs saved
  weaknesses:
  - Legend positioned using absolute pixel coordinates which could be fragile
  - Y-axis has excessive tick density making it appear cluttered
  - No interactivity or tooltips added despite Altair's strength in this area
  - Grid lines could be styled more subtly with smaller dash pattern
  image_description: The plot displays two ROC curves comparing classifier performance.
    A blue solid line represents the "Good Model" (AUC = 0.96) that rises steeply
    from the origin and hugs the top-left corner, indicating excellent classification
    performance. A yellow/gold solid line shows the "Moderate Model" (AUC = 0.71)
    with a more gradual curve. A gray dashed diagonal line represents the random classifier
    baseline (AUC = 0.50). The title "roc-curve · altair · pyplots.ai" appears at
    the top. The X-axis is labeled "False Positive Rate" (0 to 1), and the Y-axis
    is labeled "True Positive Rate" (0 to 1). A legend in the lower right clearly
    identifies all three lines with their AUC values. The plot uses a square 1:1 aspect
    ratio with subtle grid lines.
  criteria_checklist:
    visual_quality:
      score: 36
      max: 40
      items:
      - id: VQ-01
        name: Text Legibility
        score: 10
        max: 10
        passed: true
        comment: Title, axis labels, tick labels, and legend text are all clearly
          readable with appropriate font sizes
      - id: VQ-02
        name: No Overlap
        score: 8
        max: 8
        passed: true
        comment: No overlapping text elements; all labels are well-separated
      - id: VQ-03
        name: Element Visibility
        score: 7
        max: 8
        passed: true
        comment: Lines are well-sized with strokeWidth=4 for model curves and 3 for
          diagonal; however the dense tick labels on y-axis make it slightly busy
      - id: VQ-04
        name: Color Accessibility
        score: 5
        max: 5
        passed: true
        comment: Blue (#306998) and yellow (#FFD43B) provide excellent contrast and
          are colorblind-safe; gray diagonal is appropriately muted
      - id: VQ-05
        name: Layout Balance
        score: 4
        max: 5
        passed: true
        comment: Square format is appropriate for ROC curves; plot fills canvas well
          but legend positioning could be slightly better integrated
      - id: VQ-06
        name: Axis Labels
        score: 2
        max: 2
        passed: true
        comment: Descriptive labels "False Positive Rate" and "True Positive Rate"
          (no units needed for rates 0-1)
      - id: VQ-07
        name: Grid & Legend
        score: 0
        max: 2
        passed: true
        comment: Legend is placed in lower-right but overlaps slightly with the plot
          area. Grid is subtle with alpha 0.3.
    spec_compliance:
      score: 25
      max: 25
      items:
      - id: SC-01
        name: Plot Type
        score: 8
        max: 8
        passed: true
        comment: Correct ROC curve visualization with TPR vs FPR
      - id: SC-02
        name: Data Mapping
        score: 5
        max: 5
        passed: true
        comment: X=FPR, Y=TPR correctly mapped
      - id: SC-03
        name: Required Features
        score: 5
        max: 5
        passed: true
        comment: Diagonal reference line present, AUC displayed in legend, multiple
          models compared with distinct colors
      - id: SC-04
        name: Data Range
        score: 3
        max: 3
        passed: true
        comment: Axes range from 0 to 1 as specified
      - id: SC-05
        name: Legend Accuracy
        score: 2
        max: 2
        passed: true
        comment: Legend labels are accurate with AUC scores
      - id: SC-06
        name: Title Format
        score: 2
        max: 2
        passed: true
        comment: Uses correct format "roc-curve · altair · pyplots.ai"
    data_quality:
      score: 18
      max: 20
      items:
      - id: DQ-01
        name: Feature Coverage
        score: 7
        max: 8
        passed: true
        comment: Shows two models with different performance levels plus random baseline;
          demonstrates full ROC curve behavior from (0,0) to (1,1)
      - id: DQ-02
        name: Realistic Context
        score: 6
        max: 7
        passed: true
        comment: Generic model comparison scenario is plausible; could benefit from
          a more concrete domain context (e.g., medical diagnosis)
      - id: DQ-03
        name: Appropriate Scale
        score: 5
        max: 5
        passed: true
        comment: All values correctly in 0-1 range; AUC values are realistic (0.96
          good, 0.71 moderate)
    code_quality:
      score: 9
      max: 10
      items:
      - id: CQ-01
        name: KISS Structure
        score: 3
        max: 3
        passed: true
        comment: 'Linear structure: imports → data generation → ROC computation →
          plotting → save'
      - id: CQ-02
        name: Reproducibility
        score: 3
        max: 3
        passed: true
        comment: Uses np.random.seed(42)
      - id: CQ-03
        name: Clean Imports
        score: 2
        max: 2
        passed: true
        comment: Only altair, numpy, pandas imported and all used
      - id: CQ-04
        name: No Deprecated API
        score: 0
        max: 1
        passed: true
        comment: Uses np.trapezoid which is correct for newer numpy versions
      - id: CQ-05
        name: Output Correct
        score: 1
        max: 1
        passed: true
        comment: Saves as plot.png and plot.html
    library_features:
      score: 3
      max: 5
      items:
      - id: LF-01
        name: Uses distinctive library features
        score: 3
        max: 5
        passed: true
        comment: Uses Altair declarative encoding, layered charts, and configure methods
          correctly but does not leverage interactive features or tooltips that make
          Altair distinctive
  verdict: APPROVED
